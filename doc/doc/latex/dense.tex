STRUMPACK provides several rank-\/structured formats for dense matrix approximation. Included are HSS (Hierarchically Semi-\/\+Separable), BLR (Block Low Rank), HODLR (Hierarchically Off-\/\+Diagonal Low Rank), Butterfly, HODBF (Hierarchically Off-\/\+Diagonal Butterfly).\hypertarget{dense_autotoc_md22}{}\doxysubsection{Structured\+Matrix Interface}\label{dense_autotoc_md22}
We provide an interface to these different formats through a single class strumpack\+::structured\+::\+Structured\+Matrix. See the documentation for this class for more information. Multiple scenarios for construction are supported, such as


\begin{DoxyItemize}
\item Construction from a dense input matrix
\item Matrix-\/free construction, using only a matrix-\/vector product
\item Construction using only selected matrix entries
\end{DoxyItemize}

Moreover, \mbox{\hyperlink{}{Structured\+Matrix }} defines several operations, such as


\begin{DoxyItemize}
\item Matrix-\/vector multiplication (and transpose product)
\item Factorization and solve
\item Query memory usage
\item Check maximum rank
\end{DoxyItemize}

Example usage of this \mbox{\hyperlink{}{Structured\+Matrix }} class can be found in examples/dense/test\+Structured.\+cpp and examples/dense/test\+Structured\+MPI.\+cpp.

If you require additional functionality, then feel free to reach out and \mbox{\hyperlink{contact}{contact}} us.\hypertarget{dense_autotoc_md23}{}\doxysubsection{C Interface}\label{dense_autotoc_md23}
The C interface to the \mbox{\hyperlink{}{Structured\+Matrix }} class can be found in \mbox{\hyperlink{}{structured/\+Structured\+Matrix.\+h }}. An example is available in examples/dense/dstructured.\+c.\hypertarget{dense_autotoc_md24}{}\doxysubsection{Fortran Interface}\label{dense_autotoc_md24}
The Fortran interface for the structured matrix functionality is based on the C interface (which is based on the C++ class strumpack\+::structured\+::\+Structured\+Matrix), so we refer to the C and C++ interfaces for more detailed information. The Fortran interface can be found in \mbox{\hyperlink{}{structured/fortran/strumpack\+\_\+dense.\+f90 }}. A Fortran example is available in examples/dense/fstructured.\+f90.

Note that the HODLR, HODBF, Butterfly and Low Rank formats are implemented using Butterfly\+PACK, which is written in Fortran. So a Fortran user can directly use Butterfly\+PACK.\hypertarget{dense_autotoc_md25}{}\doxysubsection{Specific Formats}\label{dense_autotoc_md25}
We recommend you use the \mbox{\hyperlink{}{Structured\+Matrix }} interface. However, the following pages are specific for certain formats\+:


\begin{DoxyItemize}
\item \mbox{\hyperlink{hss_matrices}{HSS Approximation of Dense Matrices}}
\item \mbox{\hyperlink{hodlr_matrices}{HODLR Approximation of Dense Matrices}}
\item \mbox{\hyperlink{blr_matrices}{BLR Approximation of Dense Matrices}}
\end{DoxyItemize}

These are all implemented as sub-\/classes of the Structured\+Matrix class. \hypertarget{hss_matrices}{}\doxysection{HSS Approximation of Dense Matrices}\label{hss_matrices}
We recommend to use the strumpack\+::structured\+::\+Structured\+Matrix interface instead of directly using the HSS classes. See \mbox{\hyperlink{dense}{Dense Solvers }}.



{\bfseries{Figure 3}}\+: Illustration of a Hierarchically Semi-\/\+Separable (HSS) matrix. Gray blocks are dense matrices. Off-\/ diagonal blocks, on different levels of the HSS hierarchy, are low-\/rank. The low-\/rank factors of off-\/diagonal blocks of different levels are related.

The HSS include files are installed in the {\bfseries{include/\+HSS/}} subdirectory, or in {\bfseries{src/\+HSS/}}. All HSS code is in the namespace strumpack\+::\+HSS. The class for a sequential/multithreaded HSS matrix is strumpack\+::\+HSS\+::\+HSSMatrix, while the distributed memory HSS class is strumpack\+::\+HSS\+::\+HSSMatrix\+MPI. For examples of the usage of these classes, see the test code in {\bfseries{test/test\+\_\+\+HSS\+\_\+seq.\+cpp}} and {\bfseries{test/test\+\_\+\+HSS\+\_\+mpi.\+cpp}} respectively. There is also one sequential example in {\bfseries{examples/dense/\+Kernel\+Regression.\+cpp}}, which uses HSS compression for kernel matrices as used in certain machine learning applications, see below, and see for instance \mbox{\hyperlink{References}{\mbox{[}2\mbox{]}}}.

We use a simple wrapper class strumpack\+::\+Dense\+Matrix, as a wrapper around a column-\/major matrix. See the documentation for that class for more info.\hypertarget{hss_matrices_autotoc_md26}{}\doxysubsection{HSS Matrix Construction}\label{hss_matrices_autotoc_md26}
There are currently two ways to construct an HSS matrix\+:


\begin{DoxyItemize}
\item By giving an {\bfseries{explicit dense matrix as input}}. This requires that the user builds the entire matrix. Currently, our HSS compression code uses randomized sampling, which repeatedly multiplies the given dense input matrix with a randomly generated matrix. This leads to an overall O(\+N$^\wedge$2r) complexity, where r is the maximum HSS rank. This complexity, combined with the O(\+N$^\wedge$2) memory requirements mean that this way of constructing an HSS matrix can be prohibitively expensive for large matrices.
\item By {\bfseries{specifying two routines}}\+:
\begin{DoxyItemize}
\item A matrix times (multiple)vector product routine\+: Specifying a fast matrix times (multiple)vector multiplication routine will greatly speed-\/up the HSS construction phase (compared to performing the random sampling with an explicit dense matrix).
\item An element extraction routine\+: The randomized HSS construction algorithm still needs to have access to certain selected elements from the original matrix. The user needs to provide a routine to evaluate the submatrix A(\+I,\+J) for a row index set I and a column index set J.
\end{DoxyItemize}
\end{DoxyItemize}

The interfaces to construct HSS matrices in these two different ways are detailed below.

Unfortunately, many applications do not fit in the two cases listed above, i.\+e., you cannot build the dense matrix first (too expensive), or you do not have a fast matrix vector product or fast acces to individual elements. We have experimental code to construct an HODLR matrix representation for those cases, see \mbox{\hyperlink{hodlr_matrices}{HODLR }}.\hypertarget{hss_matrices_autotoc_md27}{}\doxysubsection{The HSS Cluster Tree}\label{hss_matrices_autotoc_md27}
The clustering of the HSS matrix is defined by a strumpack\+::structured\+::\+Cluster\+Tree. The strumpack\+::structured\+::\+Cluster\+Tree uses a recursive representation, a child in the tree is also a strumpack\+::structured\+::\+Cluster\+Tree. A node in this tree should always have 0 or 2 children, and the size of the tree should always be the sum of the sizes of its children. To build a whole tree use the simple constructor to specify the size n of the corresponding HSS matrix, then refine it.

To refine uniformly to a given leaf size is reached use\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{void} strumpack::structured::ClusterTree::refine(\textcolor{keywordtype}{int} leaf\_size);}

\end{DoxyCode}


or refine it manualy by adding nodes to the child vector strumpack\+::structured\+::\+Cluster\+Tree\+::c\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{// construct a basic, empty, 1 level tree}}
\DoxyCodeLine{strumpack::structured::ClusterTree t(N);}
\DoxyCodeLine{\textcolor{comment}{// uniformly refine the tree to a given leaf size}}
\DoxyCodeLine{t.refine(leaf\_size)}
\DoxyCodeLine{}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// OR manually define the tree}}
\DoxyCodeLine{strumpack::structured::ClusterTree t(N);}
\DoxyCodeLine{\textcolor{comment}{// each node should have either 0 or 2 childeren}}
\DoxyCodeLine{t.c.emplace\_back(N/2);}
\DoxyCodeLine{t.c.emplace\_back(N-\/N/2);}
\DoxyCodeLine{\textcolor{comment}{// the result is a tree with only 2 levels, which can be refined further}}

\end{DoxyCode}


Alternatively, if you have access underlying geometry that is used to construct the matrix, you can use one of the clustering algorithms, see binary\+\_\+tree\+\_\+clustering().\hypertarget{hss_matrices_autotoc_md28}{}\doxysubsection{Sequential/\+Threaded HSS Matrix Construction}\label{hss_matrices_autotoc_md28}
See the class strumpack\+::\+HSS\+::\+HSSMatrix, which is a subclass of the abstract class strumpack\+::\+HSS\+::\+HSSMatrix\+Base.

HSS matrix construction from an explicit {\bfseries{dense matrix}} can be done as follows\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{strumpack::DenseMatrix<double> A(m, n);}
\DoxyCodeLine{\textcolor{comment}{// ... fill the dense matrix A}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Create an HSS options object and set some options.}}
\DoxyCodeLine{strumpack::HSS::HSSOptions<double> opts;}
\DoxyCodeLine{opts.set\_leaf\_size(512);}
\DoxyCodeLine{opts.set\_rel\_tol(1e-\/2);}
\DoxyCodeLine{\textcolor{comment}{// allow the command line arguments to overwrite any options}}
\DoxyCodeLine{opts.set\_from\_command\_line(argc, argv);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Construct the HSS matrix from the dense matrix, using the options specified in opts.}}
\DoxyCodeLine{\textcolor{comment}{// This will use a uniform partitioning of the matrix, using a leaf size from opts.leaf\_size(),}}
\DoxyCodeLine{\textcolor{comment}{// and it will immediately start the HSS compression.}}
\DoxyCodeLine{strumpack::HSS::HSSMatrix<double> H1(A, opts);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// OR construct an HSS matrix with a given cluster/partition tree.}}
\DoxyCodeLine{strumpack::HSS::HSSMatrix<double> H2(t, opts);}
\DoxyCodeLine{\textcolor{comment}{// and compress it}}
\DoxyCodeLine{H2.compress(A, opts);}

\end{DoxyCode}


Alternatively, to construct an HSS without first building the whole dense matrix, you need to define a matrix-\/vector multiplication routine and an element extraction routine. The matrix-\/vector product should have t the following signature\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{std::function<void(}
\DoxyCodeLine{    strumpack::DenseMatrix<scalar\_t>\& Rr,  \textcolor{comment}{// input, set by compression code}}
\DoxyCodeLine{    strumpack::DenseMatrix<scalar\_t>\& Rc,  \textcolor{comment}{// input, set by compression code}}
\DoxyCodeLine{    strumpack::DenseMatrix<scalar\_t>\& Sr,  \textcolor{comment}{// output, compute as A * Rr}}
\DoxyCodeLine{    strumpack::DenseMatrix<scalar\_t>\& Sc   \textcolor{comment}{// output, compute as A\string^c * Rc or A\string^T * Rc}}
\DoxyCodeLine{)>;}

\end{DoxyCode}


where Rr and Rc are random matrices (set by the HSS compression code), and the routine should fill in Sr and Sc. This can be a functor, or a lambda function for instance. The random sample matrix Sr should be computed by the matrix-\/(multiple)vector multiplication routine as A$\ast$\+Rr. The Sr matrix will aready be allocated by the compression routine and should satisfy Sr.\+rows() == A.\+rows() and Sr.\+cols() == Rr.\+cols(). The random sample matrix Sc should be computed by the matrix-\/(multiple)vector multiplication routine as A$^\wedge$\+T$\ast$\+Rc, or A$^\wedge$\+C$\ast$\+Rc. This will aready be allocated by the compression routine and should be Sc.\+rows() == A.\+cols() and Sc.\+cols() == Rc.\+cols().

And the element extraction routine should have the signature\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{std::function<void(}
\DoxyCodeLine{    \textcolor{keyword}{const} std::vector<std::size\_t>\& I,   \textcolor{comment}{// row index set}}
\DoxyCodeLine{    \textcolor{keyword}{const} std::vector<std::size\_t>\& J,   \textcolor{comment}{// column index set}}
\DoxyCodeLine{    strumpack::DenseMatrix<scalar\_t>\& B  \textcolor{comment}{// output B == A(I,J)}}
\DoxyCodeLine{)>;}

\end{DoxyCode}


where the user is responsible for computing the elements A(\+I,\+J) and putting them into the matrix B. B will already be allocated and is of size I.\+size() x J.\+size().

The HSS construction would look as follows\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keyword}{using }DenseM\_t = strumpack::DenseMatrix<double>;}
\DoxyCodeLine{\textcolor{keyword}{auto} Amult = [\&](DenseM\_t\& Rr, DenseM\_t\& Rc, DenseM\_t\& Sr, DenseM\_t\& Sc) \{}
\DoxyCodeLine{  \textcolor{comment}{// TODO compute Sr = A * Rr}}
\DoxyCodeLine{  \textcolor{comment}{// TODO compute Sc = A\string^c * Rc}}
\DoxyCodeLine{\};}
\DoxyCodeLine{\textcolor{keyword}{auto} Aelem = [\&](\textcolor{keyword}{const} std::vector<std::size\_t>\& I,}
\DoxyCodeLine{                 \textcolor{keyword}{const} std::vector<std::size\_t>\& J,}
\DoxyCodeLine{                 DenseM\_t\& B) \{}
\DoxyCodeLine{  \textcolor{keywordflow}{for} (std::size\_t j=0; j<J.size(); j++)}
\DoxyCodeLine{    \textcolor{keywordflow}{for} (std::size\_t i=0; i<I.size(); i++)}
\DoxyCodeLine{      B(i, j) = A(I[i], J[j]); \textcolor{comment}{// get/compute elements of A}}
\DoxyCodeLine{\};}
\DoxyCodeLine{}
\DoxyCodeLine{strumpack::HSS::HSSOptions<double> opts;}
\DoxyCodeLine{opts.set\_from\_command\_line(argc, argv);}
\DoxyCodeLine{strumpack::structured::ClusterTree t(N);}
\DoxyCodeLine{t.refine(opt.leaf\_size());}
\DoxyCodeLine{strumpack::HSS::HSSMatrix<double> H(t, opts)}
\DoxyCodeLine{H.compress(Amult, Aelem, opts);}

\end{DoxyCode}
\hypertarget{hss_matrices_autotoc_md29}{}\doxysubsection{Kernel Matrix Approximation}\label{hss_matrices_autotoc_md29}
We have an optimized HSS construction algorithm for the so called kernel matrices, which arise in several applications, such as kernel ridge regression in machine learning. One can use the strumpack\+::\+HSS\+::\+HSSMatrix constructor\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{strumpack::HSS::HSSMatrix(strumpack::kernel::Kernel<scalar\_t>\& K,}
\DoxyCodeLine{                          std::vector<int>\& perm,}
\DoxyCodeLine{                          \textcolor{keyword}{const} strumpack::HSS::HSSOptions<scalar\_t>\& opts);}

\end{DoxyCode}


However, for kernel ridge regression, the strumpack\+::kernel\+::\+Kernel class provides some easy to use driver routines, see


\begin{DoxyCode}{0}
\DoxyCodeLine{strumpack::DenseMatrix<scalar\_t>}
\DoxyCodeLine{strumpack::kernel::Kernel::fit\_HSS(std::vector<scalar\_t>\& labels,}
\DoxyCodeLine{                                   \textcolor{keyword}{const} strumpack::HSS::HSSOptions<scalar\_t>\& opts);}
\DoxyCodeLine{std::vector<scalar\_t>}
\DoxyCodeLine{strumpack::kernel::Kernel::predict(\textcolor{keyword}{const} strumpack::DenseMatrix<scalar\_t>\& test,}
\DoxyCodeLine{                                   \textcolor{keyword}{const} strumpack::DenseMatrix<scalar\_t>\& weights);}

\end{DoxyCode}


There is also a Python interface to these Kernel regression routines, compatibile with scikit-\/learn, see {\bfseries{install/python/\+STRUMPACKKernel.\+py}} and {\bfseries{examples/dense/\+Kernel\+Regression.\+py}}.\hypertarget{hss_matrices_autotoc_md30}{}\doxysubsection{Limitations}\label{hss_matrices_autotoc_md30}
Currently the class strumpack\+::\+HSS\+::\+HSSMatrix\+MPI cannot be used for on a communicator with a single MPI process. In that case, one should use the sequential strumpack\+::\+HSS\+::\+HSSMatrix class. \hypertarget{hodlr_matrices}{}\doxysection{HODLR Approximation of Dense Matrices}\label{hodlr_matrices}
We recommend to use the strumpack\+::structured\+::\+Structured\+Matrix interface instead of directly using the HODLR classes. See \mbox{\hyperlink{dense}{Dense Solvers }}.

HODLR, or Hierarchically Off-\/\+Diagonal Low Rank, is a rank-\/structured format that is similar to HSS, but simpler. It uses the same weak admissibility, i.\+e, all off-\/diagonal blocks are low rank, but it does not use nested bases. Compared to HSS, HODLR theoretically has worse asymptotic complexity, but the algorithms might be faster in practice for medium sized problems.

STRUMPACK\textquotesingle{}s HODLR code uses an external library, which can be found here\+: \mbox{\hyperlink{}{\href{https://github.com/liuyangzhuan/ButterflyPACK}{\texttt{ https\+://github.\+com/liuyangzhuan/\+Butterfly\+PACK}} }}

See the \mbox{\hyperlink{installation}{Installation and Requirements}} instructions for how to configure and compile STRUMPACK with support for HODLR.

The HODLR include files are installed in the {\bfseries{include/\+HODLR/}} subdirectory, or in {\bfseries{src/\+HODLR/}}. All HODLR code is in the namespace strumpack\+::\+HODLR. The main class for sequential/multithreaded as well as distributed memory HODLR matrices is strumpack\+::\+HODLR\+::\+HODLRMatrix.

We use a simple wrapper class strumpack\+::\+Dense\+Matrix, as a wrapper around a column-\/major matrix. See the documentation for that class for more info.\hypertarget{hodlr_matrices_autotoc_md31}{}\doxysubsection{HODLR Matrix Construction}\label{hodlr_matrices_autotoc_md31}
There are currently 3 ways to construct an HODLR matrix\+:


\begin{DoxyItemize}
\item By specifying a matrix time (multiple-\/)vector product routine.
\item By specifying a matrix element evaluation routine.
\item By specifying a strumpack\+::kernel\+::\+Kernel object, containing a set of (high-\/dimensional) points and a kernel function.
\end{DoxyItemize}\hypertarget{hodlr_matrices_autotoc_md32}{}\doxysubsubsection{HODLR Construction from Element Evaluation}\label{hodlr_matrices_autotoc_md32}
Use the constructor


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{void} strumpack::HODLR::HODLRMatrix}
\DoxyCodeLine{      (\textcolor{keyword}{const} strumpack::MPIComm\& c,                          \textcolor{comment}{// MPI\_Comm wrapper}}
\DoxyCodeLine{       \textcolor{keyword}{const} strumpack::structured::ClusterTree\& tree,       \textcolor{comment}{// partition/cluster tree}}
\DoxyCodeLine{       \textcolor{keyword}{const} std::function<scalar\_t(                         \textcolor{comment}{// return value = A(i,j)}}
\DoxyCodeLine{          \textcolor{keywordtype}{int} i,                                             \textcolor{comment}{// row coordinate}}
\DoxyCodeLine{          \textcolor{keywordtype}{int} j,                                             \textcolor{comment}{// column coordinate}}
\DoxyCodeLine{        )>\& Aelem,                                           \textcolor{comment}{// element extraction routine}}
\DoxyCodeLine{       \textcolor{keyword}{const} strumpack::HODLR::HODLROptions<scalar\_t>\& opts  \textcolor{comment}{// options object}}
\DoxyCodeLine{    );}

\end{DoxyCode}


For example, to construct an HODLR approximation of a Toeplitz matrix\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{preprocessor}{\#include "{}HODLR/HODLRMatrix.hpp"{}}}
\DoxyCodeLine{}
\DoxyCodeLine{...}
\DoxyCodeLine{}
\DoxyCodeLine{strumpack::MPIComm c;  \textcolor{comment}{// defaults to MPI\_COMM\_WORLD}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keywordtype}{int} N = 1000;}
\DoxyCodeLine{strumpack::structured::ClusterTree t(N);       \textcolor{comment}{// construct a tree for an NxN matrix}}
\DoxyCodeLine{t.refine(32);                                  \textcolor{comment}{// refine the tree}}
\DoxyCodeLine{strumpack::HODLR::HODLROptions<double> opts;}
\DoxyCodeLine{opts.set\_from\_command\_line(argc, argv);        \textcolor{comment}{// optionally, parse command line options}}
\DoxyCodeLine{strumpack::HODLR::HODLRMatrix<double>}
\DoxyCodeLine{     H(c, t, [](\textcolor{keywordtype}{int} i, \textcolor{keywordtype}{int} j) \{}
\DoxyCodeLine{        \textcolor{keywordflow}{return} (i==j) ? 1. : 1./(1+abs(i-\/j)); \},}
\DoxyCodeLine{       opts);}
\DoxyCodeLine{H.factor();}
\DoxyCodeLine{...}

\end{DoxyCode}
\hypertarget{hodlr_matrices_autotoc_md33}{}\doxysubsubsection{HODLR Construction from Matrix-\/\+Vector Multiplication}\label{hodlr_matrices_autotoc_md33}
Use the constructor


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{void} strumpack::HODLR::HODLRMatrix}
\DoxyCodeLine{      (\textcolor{keyword}{const} strumpack::MPIComm\& c,                          \textcolor{comment}{// MPI\_Comm wrapper}}
\DoxyCodeLine{       \textcolor{keyword}{const} strumpack::structured::ClusterTree\& tree,       \textcolor{comment}{// partition/cluster tree}}
\DoxyCodeLine{       \textcolor{keyword}{const} std::function<\textcolor{keywordtype}{void}(                             \textcolor{comment}{// matrix-\/vector multiplication routine}}
\DoxyCodeLine{          strumpack::Trans op,                               \textcolor{comment}{// none, transpose, conjugate}}
\DoxyCodeLine{          \textcolor{keyword}{const} strumpack::DenseMatrix<scalar\_t>\& R,         \textcolor{comment}{// input (random matrix)}}
\DoxyCodeLine{          strumpack::DenseMatrix<scalar\_t>\& S                \textcolor{comment}{// output, compute as S = op(A)*R (S already allocated) }}
\DoxyCodeLine{        )>\& Amult,}
\DoxyCodeLine{       \textcolor{keyword}{const} strumpack::HODLR::HODLROptions<scalar\_t>\& opts  \textcolor{comment}{// options object}}
\DoxyCodeLine{    );}

\end{DoxyCode}


The strumpack\+::\+MPIComm object is a simple wrapper around an MPI communicator. The partition or cluster tree data structure is the same as for HSS matrices. See dense\+\_\+matrices for how to construct this tree.\hypertarget{hodlr_matrices_autotoc_md34}{}\doxysubsection{Kernel Matrix Approximation}\label{hodlr_matrices_autotoc_md34}
We have an optimized HODLR construction algorithm for the so called kernel matrices, which arise in several applications, such as kernel ridge regression in machine learning. One can use the strumpack\+::\+HODLR\+::\+HODLRMatrix constructor\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{strumpack::HODLR::HODLRMatrix(strumpack::kernel::Kernel<scalar\_t>\& K,}
\DoxyCodeLine{                              std::vector<int>\& perm,}
\DoxyCodeLine{                              \textcolor{keyword}{const} strumpack::HODLR::HODLROptions<scalar\_t>\& opts);}

\end{DoxyCode}


However, for kernel ridge regression, the strumpack\+::kernel\+::\+Kernel class provides some easy to use driver routines, see


\begin{DoxyCode}{0}
\DoxyCodeLine{strumpack::DenseMatrix<scalar\_t>}
\DoxyCodeLine{strumpack::kernel::Kernel::fit\_HODLR(\textcolor{keyword}{const} MPIComm\& c,}
\DoxyCodeLine{                                     std::vector<scalar\_t>\& labels,}
\DoxyCodeLine{                                     \textcolor{keyword}{const} strumpack::HODLR::HODLROptions<scalar\_t>\& opts);}
\DoxyCodeLine{std::vector<scalar\_t>}
\DoxyCodeLine{strumpack::kernel::Kernel::predict(\textcolor{keyword}{const} strumpack::DenseMatrix<scalar\_t>\& test,}
\DoxyCodeLine{                                   \textcolor{keyword}{const} strumpack::DenseMatrix<scalar\_t>\& weights);}

\end{DoxyCode}


There is also a Python interface to these Kernel regression routines, compatibile with scikit-\/learn, see {\bfseries{install/python/\+STRUMPACKKernel.\+py}} and {\bfseries{examples/dense/\+Kernel\+Regression\+MPI.\+py}}.\hypertarget{hodlr_matrices_autotoc_md35}{}\doxysubsection{HODLR Matrix Operations}\label{hodlr_matrices_autotoc_md35}
{\bfseries{TODO}} discuss parallel storage, mult, factor, solve, inv\+\_\+mult, etc.. \hypertarget{blr_matrices}{}\doxysection{BLR Approximation of Dense Matrices}\label{blr_matrices}
We recommend to use the strumpack\+::structured\+::\+Structured\+Matrix interface instead of directly using the BLR classes. See \mbox{\hyperlink{dense}{Dense Solvers }}.

The BLR code can be found in the src/\+BLR/ subdirectory. All BLR code is in a namespace called \mbox{\hyperlink{}{BLR}}.

The class for a sequential/multithreaded BLR matrix is \mbox{\hyperlink{}{BLRMatrix$<$scalar$>$}}.

Distributed memory BLR support is implemented in the \mbox{\hyperlink{}{BLRMatrix\+MPI$<$scalar$>$}} class. 